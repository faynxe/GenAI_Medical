{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84361bd-13b9-406e-a389-014da04fe368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install anthropic\n",
    "! pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a041aa22-cf69-4acc-ba4b-12dc6309d61d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from anthropic import Anthropic\n",
    "from botocore.config import Config\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "import json\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b301082-4a35-434d-8428-3ed1a6238046",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Bedrock model ids\n",
    "bedrock = boto3.client(service_name='bedrock',region_name='us-east-1')\n",
    "[x['modelId'] for x in bedrock.list_foundation_models()['modelSummaries'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416300f9-bfea-4c54-8110-974d8e1f11ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the bedrock runtime to invoke LLM\n",
    "config = Config(\n",
    "    read_timeout=120,\n",
    "    retries = dict(\n",
    "        max_attempts = 5 ## Handle retries\n",
    "    )\n",
    ")\n",
    "import boto3\n",
    "bedrock_runtime = boto3.client(service_name='bedrock-runtime',region_name='us-east-1',config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59a8eae-361a-4843-8aa5-5bb718cd5f7f",
   "metadata": {},
   "source": [
    "## BULK DOC PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e2e9e-785a-4a84-b627-ae9b34683ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pillow -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30986ecd-7220-4e6e-8692-64616abb87e9",
   "metadata": {},
   "source": [
    "### If you already have your files in s3 in pdf format, skip the next 4 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809c4653-eadc-42be-a558-d5bb96c4c2f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "path='images' #local path to medical image files\n",
    "shutil.rmtree(f'{path}/.ipynb_checkpoints',ignore_errors=True)\n",
    "sources=os.listdir(path)\n",
    "sources=[f\"{path}/{x}\" for x in sources]\n",
    "sources.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5fb78-68b5-4804-ba59-54147cbb4741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a64727-7519-4997-93f5-02ccc02125df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CONVERT MULTIPLE IMAGE FILES TO A PDF\n",
    "from PIL import Image  \n",
    "bucket_name=\"fairstone\" #Bucket to upload pdf files to for textract\n",
    "images = [\n",
    "    Image.open(f) for f in sources\n",
    "]\n",
    "# local path to save image as pdf\n",
    "pdf_path = \"pdf_image/pdf1.pdf\"\n",
    "    \n",
    "images[0].save(\n",
    "    pdf_path, \"PDF\" ,resolution=100.0, save_all=True, append_images=images[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8521339-c8f8-47ef-9043-1347222520ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Upload file to s3\n",
    "!aws s3 cp {pdf_path} s3://{bucket_name}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c727b9-fd5a-4c19-a4e1-1e15b6182c24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Asynchronous Textract call. \n",
    "\n",
    "TEXTRACT=boto3.client('textract')\n",
    "response = TEXTRACT.start_document_analysis(\n",
    "    DocumentLocation={\n",
    "        'S3Object': {\n",
    "           'Bucket': bucket_name, ## Bucket name holding the documents\n",
    "            'Name': pdf_path.split('/',1)[-1], # path to the pdf files in s3\n",
    "        }\n",
    "    },\n",
    "    FeatureTypes=[\n",
    "        'LAYOUT',\"TABLES\" \n",
    "    ],\n",
    "    ClientRequestToken='cdddssdatke',\n",
    "    # JobTag='string',\n",
    "    # NotificationChannel={\n",
    "    #     'SNSTopicArn': 'string',\n",
    "    #     'RoleArn': 'string'\n",
    "    # },\n",
    "    OutputConfig={\n",
    "        'S3Bucket': bucket_name,\n",
    "        'S3Prefix': 'textract_output/'\n",
    "    },\n",
    "    # KMSKeyId='string',\n",
    "   \n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b0c9e4-4cf0-437c-947b-a98b75b7cc04",
   "metadata": {},
   "source": [
    "#### Helper Textract Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b37c7e-9337-4e26-8e4e-498f7ab8027c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_consecutive_runs_refactored(number_list):\n",
    "    merged_list = [number_list[i] if i == 0 or number_list[i] != number_list[i-1] + 1 else None\n",
    "                   for i in range(len(number_list))]\n",
    "\n",
    "    return [num for num in merged_list if num is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2600902-dcef-4f96-9592-7f630c5be259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import io\n",
    "from io import BytesIO\n",
    "import sys\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def get_rows_columns_map(table_result, blocks_map):\n",
    "    rows = {}\n",
    "    scores = []\n",
    "    merged_cells = []\n",
    "    for relationship in table_result['Relationships']:\n",
    "        if relationship['Type'] == 'MERGED_CELL':\n",
    "            merged_cells.extend(blocks_map[relationship['Ids'][0]]['Relationships'][0]['Ids'])\n",
    "        if relationship['Type'] == 'CHILD':\n",
    "            for child_id in relationship['Ids']:\n",
    "                cell = blocks_map[child_id]\n",
    "                if cell['BlockType'] == 'CELL':\n",
    "                    row_index = cell['RowIndex']\n",
    "                    col_index = cell['ColumnIndex']\n",
    "                    if row_index not in rows:\n",
    "                        # create new row\n",
    "                        rows[row_index] = {}\n",
    "                    \n",
    "                    # get confidence score\n",
    "                    scores.append(str(cell['Confidence']))\n",
    "                        \n",
    "                    # get the text value\n",
    "                    rows[row_index][col_index] = {\"text\":get_text(cell, blocks_map),\"ids\":child_id}\n",
    "                    # rows[row_index][col_index]={}\n",
    "    return rows, scores, merged_cells\n",
    "\n",
    "\n",
    "def get_text(result, blocks_map):\n",
    "    text = ''\n",
    "    if 'Relationships' in result:\n",
    "        for relationship in result['Relationships']:\n",
    "            if relationship['Type'] == 'CHILD':\n",
    "                for child_id in relationship['Ids']:\n",
    "                    word = blocks_map[child_id]\n",
    "                    if word['BlockType'] == 'WORD':\n",
    "                        if \",\" in word['Text'] and word['Text'].replace(\",\", \"\").isnumeric():\n",
    "                            text += '\"' + word['Text'] + '\"' + ' '\n",
    "                        else:\n",
    "                            text += word['Text'] + ' '\n",
    "                    if word['BlockType'] == 'SELECTION_ELEMENT':\n",
    "                        if word['SelectionStatus'] =='SELECTED':\n",
    "                            text +=  'X '\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_table_csv_results(response, blocks_map=None):\n",
    "    # Get the text blocks\n",
    "    blocks=response['Blocks']\n",
    "    # pprint(blocks)\n",
    "    if not blocks_map:\n",
    "        blocks_map = {}\n",
    "    table_blocks = []\n",
    "    for block in blocks:\n",
    "        if not blocks_map:\n",
    "            blocks_map[block['Id']] = block\n",
    "        if block['BlockType'] == \"TABLE\":\n",
    "            table_blocks.append(block)\n",
    "\n",
    "    if len(table_blocks) <= 0:\n",
    "        return \"<b> NO Table FOUND </b>\"\n",
    "    \n",
    "    rwss=[]\n",
    "    merged_cellss=[]\n",
    "    csv_text=[]\n",
    "    csv = ''\n",
    "    for index, table in enumerate(table_blocks):\n",
    "        word, rws,merged_cells=generate_table_csv(table, blocks_map, index +1)\n",
    "        csv += word\n",
    "        csv += '\\n\\n'\n",
    "        rwss.append(rws)\n",
    "        merged_cellss.append(merged_cells)\n",
    "        csv_text.append(csv)\n",
    "        \n",
    "    return csv_text, rwss, merged_cellss\n",
    "\n",
    "def generate_table_csv(table_result, blocks_map, table_index):\n",
    "    rows, scores, merged_cells = get_rows_columns_map(table_result, blocks_map)\n",
    "    table_id = 'Table_' + str(table_index)\n",
    "    \n",
    "    # get cells.\n",
    "    csv = 'Table: {0}\\n\\n'.format(table_id)\n",
    "\n",
    "    for row_index, cols in rows.items():\n",
    "        for col_index, text in cols.items():\n",
    "            col_indices = len(cols.items())\n",
    "            csv += '{}'.format(text['text']) + \",\"\n",
    "        csv += '\\n'\n",
    "        \n",
    "    csv += '\\n\\n Confidence Scores % (Table Cell) \\n'\n",
    "    cols_count = 0\n",
    "    for score in scores:\n",
    "        cols_count += 1\n",
    "        csv += score + \",\"\n",
    "        if cols_count == col_indices:\n",
    "            csv += '\\n'\n",
    "            cols_count = 0\n",
    "\n",
    "    csv += '\\n\\n\\n'\n",
    "    return csv, rows, merged_cells \n",
    "\n",
    "def csv_creator(file_name, blocks_map=None):\n",
    "    result=get_table_csv_results(file_name, blocks_map)\n",
    "    if \"NO Table FOUND\" in result:\n",
    "        return \"\"\n",
    "    else:\n",
    "        table_csv, rows,merged_cells=result[0],result[1],result[2]\n",
    "        page_list=[] \n",
    "        table_string=''\n",
    "\n",
    "        table_list=[]\n",
    "        for items in rows:\n",
    "            table_dict={}\n",
    "            for row_index, cols in items.items():\n",
    "                table_dict[row_index]=[]\n",
    "                for col_index, text in cols.items():    \n",
    "\n",
    "                    col_indices = len(cols.items())\n",
    "                    if text['ids'] in merged_cells:\n",
    "                        table_string+=text[\"text\"]\n",
    "                        if table_dict[row_index]:\n",
    "                            table_dict[row_index].pop(-1)\n",
    "                        table_dict[row_index].append(table_string)\n",
    "                    else:            \n",
    "                        table_string += '{}'.format(text['text']) + \",\"\n",
    "                        table_dict[row_index].append(text[\"text\"])\n",
    "                \n",
    "                table_string += '\\n'\n",
    "            table_list.append(table_dict)\n",
    "            cell_table=[x for x in [blocks_map[x] for x in blocks_map if blocks_map[x]['BlockType']==\"TABLE\"] if text['ids']in x['Relationships'][0]['Ids']]\n",
    "            page=cell_table[0]['Page']\n",
    "            page_list.append(page)\n",
    "        import pandas as pd\n",
    "        ids = []\n",
    "        for items in rows:\n",
    "            for v1 in items.values():\n",
    "                for v2 in v1.values(): \n",
    "                    ids.append(v2['ids'])\n",
    "        \n",
    "        header=\"\"\n",
    "        page=\"\"\n",
    "        df_list=[]\n",
    "        header_list=[]\n",
    "  \n",
    "        # Check if the first row's index size mismatches the rest of the rows\n",
    "        for table_dict in table_list:\n",
    "\n",
    "            if len(table_dict.keys())>1:\n",
    "                if len(table_dict.get(1, [])) != len(table_dict.get(2, [])):\n",
    "                    header=table_dict.pop(1)\n",
    "                    columns = table_dict.pop(2)\n",
    "                # Extract the column names from the first row\n",
    "                else:\n",
    "                    if any(table_dict[1]):\n",
    "                        columns = table_dict.pop(1)\n",
    "                    else:\n",
    "                        columns = table_dict.pop(2)\n",
    "           \n",
    "                # Convert the dictionary to a DataFrame\n",
    "                try:\n",
    "                    df = pd.DataFrame.from_dict(table_dict, orient='index', columns=columns)\n",
    "                    for page in set([blocks_map[x][\"Page\"] for x in ids]):\n",
    "                        pages=page \n",
    "                except:\n",
    "                    df = pd.DataFrame.from_dict({}, orient='index', columns=columns)\n",
    "                    for page in set([blocks_map[x][\"Page\"] for x in ids]):\n",
    "                        pages=page \n",
    "            else:\n",
    "                columns = table_dict.pop(1)\n",
    "                df = pd.DataFrame.from_dict({}, orient='index', columns=columns)\n",
    "                for page in set([blocks_map[x][\"Page\"] for x in ids]):\n",
    "                        pages=page \n",
    "            df_list.append(df)\n",
    "            header_list.append(header) \n",
    "    \n",
    "        return df_list, header_list, page_list,rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7d1249-76e9-4a89-b038-1bbce5c778d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def extract_words_in_bounding_box(textract_response, holder):\n",
    "    countt=0\n",
    "    words_in_box = {}\n",
    "    page=-1\n",
    "    words=[]\n",
    "    ground_truth_lines=[]\n",
    "    ground_truth_doc={}\n",
    "    lines=[]\n",
    "    table_lines={}\n",
    "    entire_doc_lines={}\n",
    "    item_type=[]\n",
    "    for item in holder:        \n",
    "        target_page=item['Page']\n",
    "        bounding_box=item['BoundingBox']\n",
    "        layout_type=item['Type']\n",
    "        item_type.append(layout_type)\n",
    "        comptroller=1\n",
    "        orchestrator=1\n",
    "        g_orchestrator=1\n",
    "        if page!= item['Page']:\n",
    "            words=[]\n",
    "            lines=[]\n",
    "            ground_truth_lines=[]\n",
    "        page=item['Page']\n",
    "        # print(page)\n",
    "        for block in textract_response['Blocks']:\n",
    "            if  (\n",
    "                block['BlockType'] == 'LINE' and\n",
    "                'Page' in block and\n",
    "                block['Page'] == target_page and\n",
    "                'Geometry' in block \n",
    "            ):\n",
    "                box = block['Geometry']['BoundingBox']\n",
    "                # print(block['Page'])\n",
    "\n",
    "                # Check if the word's bounding box is within the specified bounding box\n",
    "                if (\n",
    "                    bounding_box['Left']-0.015*bounding_box['Left'] <= box['Left'] and\n",
    "                    bounding_box['Top']-0.015*bounding_box['Top'] <= box['Top'] and\n",
    "                    (bounding_box['Left'] + bounding_box['Width'])+0.015*(bounding_box['Left'] + bounding_box['Width']) >= box['Left'] + box['Width'] and\n",
    "                    (bounding_box['Top'] + bounding_box['Height'])+0.015*(bounding_box['Top'] + bounding_box['Height']) >= box['Top'] + box['Height']\n",
    "                ):\n",
    "                    # print(box['Left'],bounding_box['Left'])\n",
    "                    # words_in_box.append(block['Text'])\n",
    "                    lines.append(block['Text'])\n",
    "                    entire_doc_lines[block['Page']]=lines\n",
    "                    \n",
    "                    if layout_type== 'LAYOUT_TABLE' and g_orchestrator==1:\n",
    "                        ground_truth_lines.append(\"<table>\")\n",
    "                        g_orchestrator=0\n",
    "                    if len(item_type)>1 and item_type[-1]!='LAYOUT_TABLE' and item_type[-2]=='LAYOUT_TABLE' and g_orchestrator==1:\n",
    "                        ground_truth_lines.append(\"</table>\")\n",
    "                        g_orchestrator=0\n",
    "                    ground_truth_lines.append(block['Text'])\n",
    "                    ground_truth_doc[block['Page']]=ground_truth_lines\n",
    "                    \n",
    "                    \n",
    "                if layout_type !='LAYOUT_TABLE':\n",
    "                    box = block['Geometry']['BoundingBox']\n",
    "                # print(block['Page'])\n",
    "\n",
    "                # Check if the word's bounding box is within the specified bounding box\n",
    "                    if (\n",
    "                        bounding_box['Left']-0.015*bounding_box['Left'] <= box['Left'] and\n",
    "                        bounding_box['Top']-0.015*bounding_box['Top'] <= box['Top'] and\n",
    "                        (bounding_box['Left'] + bounding_box['Width'])+0.015*(bounding_box['Left'] + bounding_box['Width']) >= box['Left'] + box['Width'] and\n",
    "                        (bounding_box['Top'] + bounding_box['Height'])+0.015*(bounding_box['Top'] + bounding_box['Height']) >= box['Top'] + box['Height']\n",
    "                    ):\n",
    "                        # print(box['Left'],bounding_box['Left'])\n",
    "                        # words_in_box.append(block['Text'])\n",
    "                        words.append(block['Text'])\n",
    "                        words_in_box[block['Page']]=words\n",
    "                if layout_type =='LAYOUT_TABLE':\n",
    "                    # orchestrator=comptroller\n",
    "                    if comptroller ==1:\n",
    "                        countt+=1\n",
    "                        words.append(\"<table>\")\n",
    "                        # words.append(table)\n",
    "                        words_in_box[block['Page']]=words\n",
    "                        comptroller=0\n",
    "                    \n",
    "                    box = block['Geometry']['BoundingBox']\n",
    "                    # print(block['Page'])\n",
    "\n",
    "                    # Check if the word's bounding box is within the specified bounding box\n",
    "                    if (\n",
    "                        bounding_box['Left']-0.015*bounding_box['Left'] <= box['Left'] and\n",
    "                        bounding_box['Top']-0.015*bounding_box['Top'] <= box['Top'] and\n",
    "                        (bounding_box['Left'] + bounding_box['Width'])+0.015*(bounding_box['Left'] + bounding_box['Width']) >= box['Left'] + box['Width'] and\n",
    "                        (bounding_box['Top'] + bounding_box['Height'])+0.015*(bounding_box['Top'] + bounding_box['Height']) >= box['Top'] + box['Height']\n",
    "                    ):\n",
    "                        if block['Page'] in table_lines:\n",
    "    #                     # # print(table_lines)\n",
    "                            if orchestrator==1:\n",
    "                                if not (block['Text'] in table_lines[block['Page']] or block['Text']+\" xxxxxx\" in table_lines[block['Page']]):\n",
    "                                    table_lines[block['Page']].extend([block['Text']+\" xxxxxx\"])\n",
    "                                    # print(block['Page'],[block['Text']+\" xxxxxxORCH\"])\n",
    "                                    orchestrator=0\n",
    "                            else:\n",
    "                                # continue\n",
    "                                if not block['Text'] in table_lines[block['Page']]:\n",
    "                                    table_lines[block['Page']].extend([block['Text']])\n",
    "                        else:\n",
    "                        # continue\n",
    "                            table_lines[block['Page']]=[block['Text']+\" xxxxxx\"]\n",
    "                            # print(block['Page'],[block['Text']+\" xxxxxx\"])\n",
    "                            orchestrator=0\n",
    "\n",
    "    return words_in_box, table_lines,entire_doc_lines, ground_truth_doc#'\\n'.join(words_in_box)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04eff6e-4428-4546-acbb-d124a351f82e",
   "metadata": {},
   "source": [
    "## EXTARCT DOCUMENT INTELLIGENTLY PRESERVING THE ORDER AND LAYOUT OF THE DOCUMENT CONTENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e4026c-7f40-414e-80fe-b2543d8151d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# poll for response\n",
    "import time\n",
    "status=\"\"\n",
    "while status != 'SUCCEEDED':\n",
    "    responses1 = TEXTRACT.get_document_analysis(\n",
    "        JobId=response['JobId']\n",
    "\n",
    "    )\n",
    "    status=responses1['JobStatus']\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5143c93c-f102-4307-80ec-07108f59090a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "responses1 = TEXTRACT.get_document_analysis(\n",
    "    JobId=response['JobId'], \n",
    ")\n",
    "geom=[]\n",
    "blocks_map = {}\n",
    "doc=[]\n",
    "words_only=[]\n",
    "table_holder={}\n",
    "table_lines={}\n",
    "non_layout_table_holder={}\n",
    "ground_truth_doc={}\n",
    "next_tokens=[]\n",
    "complete_response_list=[]\n",
    "for block in responses1['Blocks']:\n",
    "    holder={}\n",
    "    if block['BlockType'] in [\n",
    "        # 'LAYOUT_FIGURE',\n",
    " # 'LAYOUT_FOOTER',\n",
    " 'LAYOUT_HEADER',\n",
    " 'LAYOUT_PAGE_NUMBER',\n",
    " 'LAYOUT_SECTION_HEADER',\n",
    " 'LAYOUT_TEXT',\n",
    " 'LAYOUT_TITLE',\n",
    "         'LAYOUT_TABLE',\n",
    "       \n",
    "                             ]:\n",
    "        holder['BoundingBox']=block['Geometry']['BoundingBox']\n",
    "        holder[\"Page\"]=block['Page']\n",
    "        holder[\"Type\"]=block['BlockType']\n",
    "        geom.append(holder)\n",
    " \n",
    "    \n",
    "    blocks_map[block['Id']] = block\n",
    "\n",
    "        \n",
    "\n",
    "if \"NextToken\" in responses1.keys():\n",
    "    next_token=responses1['NextToken']\n",
    "    while next_token:\n",
    "        responses1 = TEXTRACT.get_document_analysis(\n",
    "                    JobId=response['JobId'],\n",
    "                    # MaxResults=123,\n",
    "                    NextToken=next_token,\n",
    "                    )\n",
    "        for block in responses1['Blocks']:\n",
    "            holder={}\n",
    "            if block['BlockType'] in [\n",
    "                    # 'LAYOUT_FIGURE',\n",
    "                     # 'LAYOUT_FOOTER',\n",
    "                     'LAYOUT_HEADER',\n",
    "                     'LAYOUT_PAGE_NUMBER',\n",
    "                     'LAYOUT_SECTION_HEADER',\n",
    "                     'LAYOUT_TEXT',\n",
    "                     'LAYOUT_TITLE',\n",
    "               \n",
    "                 'LAYOUT_TABLE',]:\n",
    "                holder['BoundingBox']=block['Geometry']['BoundingBox']\n",
    "                holder[\"Page\"]=block['Page']\n",
    "                holder[\"Type\"]=block['BlockType']\n",
    "                geom.append(holder)\n",
    "            blocks_map[block['Id']] = block\n",
    "        if \"NextToken\" in responses1.keys():\n",
    "            next_token=responses1['NextToken']\n",
    "        else:\n",
    "            next_token=\"\"\n",
    "            break\n",
    "\n",
    "responses1 = TEXTRACT.get_document_analysis(\n",
    "    JobId=response['JobId'],\n",
    "    # MaxResults=123,\n",
    "    # NextToken=nt,\n",
    ")\n",
    "result = extract_words_in_bounding_box(responses1, geom)\n",
    "doc.append(result[0])\n",
    "table_lines.update(result[1])\n",
    "non_layout_table_holder.update(result[2])\n",
    "ground_truth_doc.update(result[-1])\n",
    "\n",
    "table_result=csv_creator(responses1,blocks_map)\n",
    "if table_result:\n",
    "    table, header,pages=table_result[0], table_result[1],table_result[2]\n",
    "    \n",
    "    for ids,page in enumerate(pages):\n",
    "        doc\n",
    "        if page in table_holder:\n",
    "            table_holder[page].extend([header[ids]]+[table[ids]])\n",
    "        else:            \n",
    "            dummy=[]\n",
    "            dummy.extend([header[ids]]+[table[ids]])\n",
    "            table_holder[int(page)]= dummy\n",
    "if \"NextToken\" in responses1.keys():\n",
    "    next_token=responses1['NextToken']           \n",
    "    while next_token:\n",
    "        responses1 = TEXTRACT.get_document_analysis(\n",
    "            JobId=response['JobId'],\n",
    "            # MaxResults=123,\n",
    "            NextToken=next_token,\n",
    "        )\n",
    "\n",
    "        table_result=csv_creator(responses1,blocks_map)\n",
    "        if table_result:\n",
    "            table, header,pages=table_result[0], table_result[1],table_result[2]\n",
    "\n",
    "            for ids,page in enumerate(pages):\n",
    "                if page in table_holder:\n",
    "                    table_holder[page].extend([header[ids]]+[table[ids]])\n",
    "                else:      \n",
    "                    dummy=[]\n",
    "                    dummy.extend([header[ids]]+[table[ids]])\n",
    "                    table_holder[int(page)]= dummy\n",
    "\n",
    "          \n",
    "        next_tokens.append(next_token)\n",
    "        result = extract_words_in_bounding_box(responses1, geom)    \n",
    "        doc.append(result[0])\n",
    "        table_lines.update(result[1])\n",
    "        non_layout_table_holder.update(result[2])   \n",
    "        ground_truth_doc.update(result[-1])      \n",
    "        if \"NextToken\" in responses1.keys():\n",
    "            next_token=responses1['NextToken']\n",
    "        else:\n",
    "            next_token=\"\"\n",
    "            break\n",
    "\n",
    "for d in doc:\n",
    "    for k, v in d.items():\n",
    "        layout_table_count=v.count('<table>')\n",
    "        if k in table_holder.keys():\n",
    "            non_layout_table_count=len(table_holder[k])/2 # Table_holder has header and tables in list \n",
    "        else:\n",
    "            non_layout_table_count=0\n",
    "        if layout_table_count == non_layout_table_count:\n",
    "            continue\n",
    "        elif non_layout_table_count==0:\n",
    "            table_index_posts=[index for index, element in enumerate(v) if element == '<table>']\n",
    "            merged_list_refactored = merge_consecutive_runs_refactored(table_index_posts)\n",
    "\n",
    "            for ids in merged_list_refactored:\n",
    "                #index of all tables in extracted text\n",
    "                dynamic_table_index_posts=[index for index, element in enumerate(v) if element == '<table>']\n",
    "                # handle consecutive tables series\n",
    "                dynamic_merged_list_refactored= merge_consecutive_runs_refactored(dynamic_table_index_posts)\n",
    "                table_index_pos=v.index(\"<table>\")  \n",
    "                if table_index_pos+1 in dynamic_table_index_posts: # if consecutive tables\n",
    "                    if len(dynamic_merged_list_refactored)>1:\n",
    "                        next_non_consecutive_item=dynamic_merged_list_refactored[dynamic_merged_list_refactored.index(table_index_pos)+1]\n",
    "                        last_consecutive_series_item=dynamic_table_index_posts[dynamic_table_index_posts.index(next_non_consecutive_item)-1]\n",
    "                    else:\n",
    "                        last_consecutive_series_item=dynamic_table_index_posts[-1]\n",
    "\n",
    "                    if dynamic_merged_list_refactored[0]!=len(v): #Check that table in text is not the last item\n",
    "                        # index for the word trailing the table, handle for multiple occurence of that word- in the doc\n",
    "                        index_stopper=[i for i in range(len(non_layout_table_holder[2]) - 1) if non_layout_table_holder[2][i] == v[last_consecutive_series_item+1] and non_layout_table_holder[2][i + 1] ==  v[last_consecutive_series_item+2]][0]\n",
    "\n",
    "                        replace_text=non_layout_table_holder[k][table_index_pos-1:non_layout_table_holder[k].index(v[last_consecutive_series_item+1],index_stopper)][1:]\n",
    "                        v[table_index_pos:last_consecutive_series_item+1]=replace_text\n",
    "                    else:\n",
    "                        replace_text=non_layout_table_holder[k][table_index_pos-1:][1:]\n",
    "                        v[table_index_pos:last_consecutive_series_item+1]=replace_text\n",
    "                else:  # No consecutive table series\n",
    "                    replace_text=non_layout_table_holder[k][non_layout_table_holder[k].index(v[table_index_pos-1]):non_layout_table_holder[k].index(v[table_index_pos+1])][1:]\n",
    "                    v[table_index_pos:table_index_pos+1]=replace_text\n",
    "        elif non_layout_table_count>layout_table_count:\n",
    "            non_layout_page_word_count=[]\n",
    "            for i in range(layout_table_count*2):\n",
    "                non_layout_page_word_count.extend(table_holder[k][i])\n",
    "            length_of_non_layout_page=len(\" \".join(non_layout_page_word_count).split())+len(\" \".join(v).split())-layout_table_count\n",
    "            length_of_layout_page=len(\" \".join(non_layout_table_holder[k]).split())\n",
    "            if length_of_layout_page>length_of_non_layout_page and (abs(length_of_layout_page-length_of_non_layout_page)/max(length_of_layout_page,length_of_non_layout_page))>0.2:\n",
    "                v.insert(v.index(\"<table>\")+1,\"<table>\")\n",
    "\n",
    "table_count_list={}\n",
    "for d in doc:\n",
    "    for k, v in d.items():\n",
    "        table_count_list[k]=v.count('<table>')\n",
    "\n",
    "\n",
    "table_count_lists = []\n",
    "for k, v in table_count_list.items():\n",
    "    if v != 0:\n",
    "        table_count_lists.extend([k]*v)\n",
    "\n",
    "doc_layout_extract={}  \n",
    "if not len(table_count_lists) or  not len([x[\"Page\"] for x in  geom if x['Type']==\"LAYOUT_TABLE\"]):\n",
    "    print(\"NO TABLES FOUND\")\n",
    "    for item in doc:\n",
    "        for k, v in item.items():\n",
    "            doc_layout_extract[k]=v\n",
    "else:\n",
    "    for d in doc:\n",
    "        for k, v in d.items():\n",
    "            if v.count(\"<table>\")>1:\n",
    "                txt=v\n",
    "                ids=0           \n",
    "                for count in range(v.count(\"<table>\")):                              \n",
    "                    header_and_table=f\"{table_holder[k][ids]}\\n<tables>{table_holder[k][ids+1].to_csv(index=False, sep='|')}</tables>\"\n",
    "                    if count+1<= table_lines[k].count(\"xxxxxx\"):\n",
    "                        header_before_table=[x for x in table_lines[k] if \"xxxxxx\" in x][count].split(\"xxxxxx\")[0]\n",
    "                        if not header_before_table in header_and_table:\n",
    "                            header_and_table=f\"{header_before_table}\\n{header_and_table}\"\n",
    "                    \n",
    "                    table_holder_index=txt.index(\"<table>\")\n",
    "                    txt[table_holder_index]=header_and_table\n",
    "                    ids+=2\n",
    "                doc_layout_extract[k]=txt\n",
    "            elif v.count(\"<table>\")==1:\n",
    "                \n",
    "                txt=v\n",
    "                header_and_table=f\"{table_holder[k][0]}\\n<tables>{table_holder[k][1].to_csv(index=False, sep='|')}</tables>\"\n",
    "                header_before_table=[x for x in table_lines[k] if \"xxxxxx\" in x][0].split(\"xxxxxx\")[0]\n",
    "                if not header_before_table in header_and_table:\n",
    "                    header_and_table=f\"{header_before_table}\\n{header_and_table}\"\n",
    "                table_holder_index=txt.index(\"<table>\")\n",
    "                txt[table_holder_index]=header_and_table\n",
    "                \n",
    "                doc_layout_extract[k]=txt\n",
    "            else:\n",
    "                doc_layout_extract[k]=v\n",
    "    for k, v in ground_truth_doc.items():\n",
    "        # table_idx=0\n",
    "        page_table_idx=[doc_layout_extract[k].index(x) for x in doc_layout_extract[k] if \"<tables>\" in x]\n",
    "        ground_truth_table_ids=[ground_truth_doc[k].index(x) for x in ground_truth_doc[k] if \"<table>\" in x]\n",
    "        if page_table_idx:\n",
    "            for table_count,table_idx in enumerate(ground_truth_table_ids):\n",
    "                page_tab=doc_layout_extract[k][page_table_idx[table_count]]\n",
    "                page_tab_to_list=page_tab.split(\"\\n\")\n",
    "                ground_truth_table_header=ground_truth_doc[k][table_idx+1]\n",
    "                page_tab_headers=page_tab_to_list[0] if page_tab_to_list[0] else page_tab_to_list[1]\n",
    "                if ground_truth_table_header:\n",
    "                    found = ground_truth_table_header in page_tab_headers #any(result_table_header in item for item in tab_headers)\n",
    "                    if found:\n",
    "                        continue\n",
    "                    else:\n",
    "                        doc_layout_extract[k][page_table_idx[table_count]]=f\"{ground_truth_table_header}\\n\"+page_tab\n",
    "                else:\n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9679eca-9d2e-4e13-9cef-5b4ebf730dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Extracted document content into a dictionary with key as page number and value as page content read by line \n",
    "doc_layout_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3dfeed-2544-4ec8-b71c-b112aa4caadc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Merge the lines of of the extracted pdf dictionary to a single coherent text\n",
    "document_text=\"\"\n",
    "for k, v in doc_layout_extract.items():\n",
    "    document_text+=\"\\n\".join(v)\n",
    "    document_text+=\"\\n\\n\"\n",
    "print(document_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946a241f-b30f-419b-889b-d95acbb089c8",
   "metadata": {},
   "source": [
    "## Different Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a19dedf-a469-4963-98c7-d0421e4ecb89",
   "metadata": {},
   "source": [
    "#### Summarization prompt templae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b4aee-240e-4329-bbc5-f6561d1c6b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2=f\"\"\"\\n\\nHuman:\n",
    "You are a tenured medical doctor.\n",
    "\n",
    "Here is a patient's medical documents below:\n",
    "<medical_documents>\n",
    "{document_text}\n",
    "</medical_documents>\n",
    "\n",
    "Read through the medical documents and understand the patient's record. Think about all the medical information captured within the documents including any:\n",
    "- medications,\n",
    "- dates and places,\n",
    "- injury/illness,\n",
    "- comorbidities,\n",
    "- findings,\n",
    "- treatments,\n",
    "- diagnosis.\n",
    "Put your thoughts in <thinking> xml tags.\n",
    "\n",
    "After reading and thinking through the document, generate a comprehensive medical summary of the patient that captures all medical information including:\n",
    "- medications,\n",
    "- dates and places,\n",
    "- injury/illness: how/when and where it occured,,\n",
    "- past comorbidities and impact on any current injury,\n",
    "- subjective findings: patient reported symptoms, feelings pain level etc.,\n",
    "- objective findings: pysician observed findings,\n",
    "- treatments: current and past,\n",
    "- diagnosis: diagnosis codes with their full descriptions and explanation.\n",
    "\n",
    "Your summary should be sectioned by each topics aligned above.\\n\\nAssistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14efff87-2533-4faa-9856-89c688a06126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "inference_modifier = {'max_tokens_to_sample':1000, \n",
    "                      \"temperature\":0.1,\n",
    "                      # \"top_k\":250,\n",
    "                      # \"top_p\":1,               \n",
    "                     }\n",
    "llm = Bedrock(model_id='anthropic.claude-v2', client=bedrock_runtime, model_kwargs = inference_modifier,\n",
    "              streaming=True,  # Toggle this to turn streaming on or off\n",
    "              callbacks=[StreamingStdOutCallbackHandler() ])\n",
    "\n",
    "response = llm(prompt2)\n",
    "if '<thinking>' in response:\n",
    "    idx1 = response.index('<thinking>')\n",
    "    idx2 = response.index('</thinking>')\n",
    "    thought_step=response[idx1 + len('<thinking>') + 1: idx2]\n",
    "    response=response[idx2 + len('</thinking>') + 1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bf9a51-6f1f-4f64-aaaf-e4c55c4dbcd5",
   "metadata": {},
   "source": [
    "#### Q&A prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0b6bcb-3508-4ecb-9b29-a0cf1bc19bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question=\"What date did the patient visit the clinic?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb0c31-e3b9-4f22-842a-ee47070e9fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt3=f\"\"\"\\n\\nHuman:\n",
    "You are a tenured medical doctor. You will be providing factual answers about a patient based on their medical document.\n",
    "\n",
    "Here is a patient's medical documents below:\n",
    "<medical_documents>\n",
    "{document_text}\n",
    "</medical_documents>\n",
    "\n",
    "After reading through the document, provide an answer to a user question below:\n",
    "{question}\n",
    "\\n\\nAssistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee60b32-3baf-4c4d-8fe2-6594fcc05611",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "inference_modifier = {'max_tokens_to_sample':500, \n",
    "                      \"temperature\":0.1,\n",
    "                      # \"top_k\":250,\n",
    "                      # \"top_p\":1,               \n",
    "                     }\n",
    "llm = Bedrock(model_id='anthropic.claude-v2', client=bedrock_runtime, model_kwargs = inference_modifier,\n",
    "              streaming=True,  # Toggle this to turn streaming on or off\n",
    "              callbacks=[StreamingStdOutCallbackHandler() ])\n",
    "\n",
    "response = llm(prompt3)\n",
    "if '<thinking>' in response:\n",
    "    idx1 = response.index('<thinking>')\n",
    "    idx2 = response.index('</thinking>')\n",
    "    thought_step=response[idx1 + len('<thinking>') + 1: idx2]\n",
    "    response=response[idx2 + len('</thinking>') + 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a89c409-87d0-42cf-95d2-063687dd1cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
